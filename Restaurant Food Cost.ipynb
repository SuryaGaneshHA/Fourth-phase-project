{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27341895-07d4-4f16-9c47-bfc520fce483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restaurant Food Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee9a867-a170-4e6f-ad66-396e082c67e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12690 entries, 0 to 12689\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   TITLE          11687 non-null  object\n",
      " 1   RESTAURANT_ID  12690 non-null  int64 \n",
      " 2   CUISINES       12690 non-null  object\n",
      " 3   TIME           12690 non-null  object\n",
      " 4   CITY           12578 non-null  object\n",
      " 5   LOCALITY       12592 non-null  object\n",
      " 6   RATING         12688 non-null  object\n",
      " 7   VOTES          11486 non-null  object\n",
      " 8   COST           12690 non-null  int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 892.4+ KB\n",
      "None\n",
      "               TITLE  RESTAURANT_ID  \\\n",
      "0      CASUAL DINING           9438   \n",
      "1  CASUAL DINING,BAR          13198   \n",
      "2      CASUAL DINING          10915   \n",
      "3        QUICK BITES           6346   \n",
      "4     DESSERT PARLOR          15387   \n",
      "\n",
      "                                     CUISINES  \\\n",
      "0                 Malwani, Goan, North Indian   \n",
      "1              Asian, Modern Indian, Japanese   \n",
      "2  North Indian, Chinese, Biryani, Hyderabadi   \n",
      "3                            Tibetan, Chinese   \n",
      "4                                    Desserts   \n",
      "\n",
      "                                     TIME     CITY        LOCALITY RATING  \\\n",
      "0  11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)    Thane  Dombivali East    3.6   \n",
      "1                    6pm – 11pm (Mon-Sun)  Chennai       Ramapuram    4.2   \n",
      "2     11am – 3:30pm, 7pm – 11pm (Mon-Sun)  Chennai      Saligramam    3.8   \n",
      "3                 11:30am – 1am (Mon-Sun)   Mumbai     Bandra West    4.1   \n",
      "4                    11am – 1am (Mon-Sun)   Mumbai     Lower Parel    3.8   \n",
      "\n",
      "       VOTES  COST  \n",
      "0   49 votes  1200  \n",
      "1   30 votes  1500  \n",
      "2  221 votes   800  \n",
      "3   24 votes   800  \n",
      "4  165 votes   300  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the train and test datasets\n",
    "train_data = pd.read_excel(\"https://github.com/FlipRoboTechnologies/ML-Datasets/raw/main/Restaurant%20Food%20Cost/Data_Train.xlsx\")\n",
    "test_data = pd.read_excel(\"https://github.com/FlipRoboTechnologies/ML-Datasets/raw/main/Restaurant%20Food%20Cost/Data_Test.xlsx\")\n",
    "\n",
    "# Display basic information about the train dataset\n",
    "print(train_data.info())\n",
    "\n",
    "# Display the first few rows of the train dataset\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96108d71-8ac7-412c-8830-49fd1de03222",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mE:\\Data Science\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_encode.py:224\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mE:\\Data Science\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mE:\\Data Science\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mE:\\Data Science\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_encode.py:158\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'unknown'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m     train_data[col] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(train_data[col])\n\u001b[0;32m     22\u001b[0m     test_data[col] \u001b[38;5;241m=\u001b[39m test_data[col]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m s: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m label_encoder\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01melse\u001b[39;00m s)\n\u001b[1;32m---> 23\u001b[0m     test_data[col] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mtransform(test_data[col])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Splitting the dataset into features and target variable\u001b[39;00m\n\u001b[0;32m     26\u001b[0m X \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOST\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mE:\\Data Science\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mE:\\Data Science\\Anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:139\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _encode(y, uniques\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[1;32mE:\\Data Science\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_encode.py:226\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'unknown'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load the train and test datasets\n",
    "train_data = pd.read_excel(\"https://github.com/FlipRoboTechnologies/ML-Datasets/raw/main/Restaurant%20Food%20Cost/Data_Train.xlsx\")\n",
    "test_data = pd.read_excel(\"https://github.com/FlipRoboTechnologies/ML-Datasets/raw/main/Restaurant%20Food%20Cost/Data_Test.xlsx\")\n",
    "\n",
    "# Data Preprocessing\n",
    "# Handling missing values\n",
    "train_data.fillna(\"unknown\", inplace=True)\n",
    "test_data.fillna(\"unknown\", inplace=True)\n",
    "\n",
    "# Encoding categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['TITLE', 'CUISINES', 'CITY', 'LOCALITY']\n",
    "for col in categorical_columns:\n",
    "    train_data[col] = label_encoder.fit_transform(train_data[col])\n",
    "    test_data[col] = test_data[col].map(lambda s: 'unknown' if s not in label_encoder.classes_ else s)\n",
    "    test_data[col] = label_encoder.transform(test_data[col])\n",
    "\n",
    "# Splitting the dataset into features and target variable\n",
    "X = train_data.drop(['COST'], axis=1)\n",
    "y = train_data['COST']\n",
    "\n",
    "# Splitting the dataset into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred_train = rf_regressor.predict(X_train)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Training RMSE:\", train_rmse)\n",
    "print(\"Training MAE:\", train_mae)\n",
    "\n",
    "y_pred_val = rf_regressor.predict(X_val)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "print(\"Validation MAE:\", val_mae)\n",
    "\n",
    "# Predictions on the test dataset\n",
    "test_predictions = rf_regressor.predict(test_data)\n",
    "\n",
    "# Saving predictions to a CSV file\n",
    "test_data['COST'] = test_predictions\n",
    "test_data[['RESTAURANT_ID', 'COST']].to_csv(\"predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b8a4c-632a-41e9-8675-a66dbd9f140d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
